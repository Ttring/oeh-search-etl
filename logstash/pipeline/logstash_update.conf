input {
    jdbc {
        jdbc_connection_string => "jdbc:postgresql://postgres:5432/search"
        jdbc_user => "search"
        jdbc_password => "admin"
        jdbc_driver_class => "org.postgresql.Driver"
        statement => 'SELECT DISTINCT ON (rm.uuid) rm.uuid as id, CAST(data as text), s.id as source_id,
                        s.name as source_name, s.url as source_url, rm.last_updated,
                        (SELECT COUNT(*) from "references_metadata" WHERE source = rm.source) AS source_total_count,
						(SELECT CAST(ARRAY_TO_JSON(ARRAY_AGG(ROW_TO_JSON(c))) AS TEXT) FROM collections AS c WHERE c.uuid = ANY(ARRAY(SELECT cr.collection_uuid FROM collections_references AS cr WHERE cr.reference_uuid = rm.uuid))) as collection_json
                        FROM "references_metadata" rm 
                        LEFT JOIN sources s ON (rm.source = s.id) 
                        LEFT JOIN "references" r ON (rm.uuid = r.uuid) 
                        WHERE
                            r.enabled = true AND (
							    rm.last_updated > :sql_last_value OR 
							    r.last_updated > :sql_last_value OR 
							    (SELECT MAX(cr.last_updated) FROM collections_references AS cr WHERE cr.reference_uuid = rm.uuid GROUP BY cr.reference_uuid) > :sql_last_value
                            )
                        ORDER BY rm.uuid, s.ranking DESC, rm.last_updated DESC'
        tracking_column => "last_modified"
        tracking_column_type => "timestamp"
        use_column_value => false

        ## every 15 seconds
        schedule => "*/15 * * * * *"
        lowercase_column_names => false
    }
}
filter {
    mutate {
        rename => {"source_id" => "[source][id]"}
        rename => {"source_name" => "[source][name]"}
        rename => {"source_url" => "[source][url]"}
        rename => {"source_total_count" => "[source][total_count]"}
    }
    json {
        source => "data"
    }
    mutate {
        rename => {"valuespaces" => "[valuespaces_raw]"}
    }
    json {
        source => "collection_json"
        target => "collection"
    }
    http {
        url => "http://valuespace_converter:5010/transform"
        verb => "POST"
        body => "%{[valuespaces_raw]}"
        target_body => "valuespaces"
    }
    prune {
        blacklist_names => [ "collection_json", "data", "doc", "@version", "@timestamp" ]
    }
}
output {
    #stdout { }
    elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "search_idx"
        action => update
        document_id => "%{[id]}"
        doc_as_upsert => true
        #user => "elastic"
        #password => "changethisinproduction"
        # seems not working properly, is now moved to docker-entrypoint
        #template => "/usr/share/logstash/templates/elastic-index.json"
        #template_name => "search_idx"
        #template_overwrite => true
    }
}